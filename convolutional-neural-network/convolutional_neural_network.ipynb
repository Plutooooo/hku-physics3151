{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network ( CNN )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>In deep learning, a convolutional neural network (CNN) is a class of deep neural networks, most commonly applied to analyzing visual imagery. We introduce it here with two examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>The first example is using CNN to identify images of digits.\n",
    "<br>Data source:https://www.kaggle.com/dingli/digits-recognition-with-cnn-keras/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>The images are kept as matrices, each row containing 784 pixels and label of the digit in the first column as shown below. Considering the limit of memory here, we just take part of the whole data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"https://quantummc.xyz/wp-content/uploads/2020/07/hku_phys3151_cnn_example1.csv\")\n",
    "train = train[0:4200]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>From the training data, we take the labels as Y (result) and the rest as X (input)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Y_train = train[\"label\"]\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>As shown above, we count the numbers of different digits, and the result turns out that they have close values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>To have a view at the relationship between the vectors of pixels and the images, we take the 4th row of the training data as example, we show the image and use the label as the title, which match well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "img_eg=np.array(X_train)[3].reshape(28,28)\n",
    "plt.imshow(img_eg,cmap='gray')\n",
    "plt.title(np.array(Y_train)[3])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>Next, we set the value of pixels to be within the range of 0 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "#test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>Since we want the pixels of each image to be matrices and Keras (which we are gonna use to build the CNN) needs an extra dimension in the end which correspond to channels(it's 1 here because the images are gray scaled), we reshape the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(4200,28,28,1)\n",
    "#test = test.values.reshape(28000,28,28,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>The initial Y are the labels which are 0,1,2.... For identification, we convert them into vectors, and thus for example:<br> 2 becomes [0,0,1,0,0,0,0,0,0,0] <br> 0 becomes [1,0,0,0,0,0,0,0,0,0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>At the last step of data preparation, split the data into train and test sets(here we take only $\\frac{1}{10}$ of the data as test sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>There are different parts in CNN:\n",
    "<br>1.$\\underline{Convolution\\ \\ Layer}$: Take a small matrix as the feature(kernel, filter), which can be a n by n matrix. Successively, convolve each part(size determined by feature) of the initial matrix and the feature, and we get a feature map as a result.\n",
    "<br>To avoid decreasing the size after convolution, we use $\\underline{padding}$ here, normally adding 0s to the edges.\n",
    "<br><br>2.$\\underline{Activation\\ \\ Function}$: we use Relu(Rectified Linear Units) here, whose fomula is simple: $f(x)=max(0,x)$, and thus the negative values are turned into 0 while the positive values remain.\n",
    "<br><br>3.$\\underline{Pooling}$: Pooling can shrink a large image while retaining important information. Here, we use Max Pooling: Usually, the pooling matrix is 2 by 2 size, the maximum value in the 2\\*2 size block in the input image is taken as the resulting pixel value.\n",
    "<br><br>4.$\\underline{Fully\\ \\ Connected\\ \\ Layers}$: In the fully connected layers below, we flatten the pooled feature maps into vectors. Every value we get in the vectors votes for the result, realized by the activation functions. Here, we also include softmax function, the formula of which is: $P=\\frac{e^{x^{T}W_j}}{\\sum_ke^{x^TW_k}}$. The result represents the probability of the type of the output.\n",
    "<br><br>In the CNN built below, Dropout is used, where randomly selected neurons are ignored during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 8, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (28,28,1))) \n",
    "#kernel size refers to the size of the feature matrix\n",
    "#filters refer to the number of output filters in the convolution\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))      #strides refer to the factor by which to downscale.\n",
    "model.add(Dropout(0.25))\n",
    "#fully connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))   #the first number in the () of Dense refers to the dimension of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>After the construction of the strcture of CNN, we need to set the optimizer. Here we choose Adam, which is an algorithm for performing a stepwise optimization on stochastic objective functions, and the parameters are the ones mostly used in machine learning.\n",
    "<br>For the loss, we use categorical_crossentropy:$$CCE = -\\frac{1}{N}\\sum_{i=0}^N\\sum_{j=0}^Jy_{i,j}\\cdot log(P_{i,j})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>The training process can consist of several epochs, one epoch means one forward pass and one backward pass of all the training examples and batch size means the number of training examples in one forward/backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "epochs = 10  # for better result increase the epochs\n",
    "batch_size=200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>Then, we fit the model with both the training set and validation set which evaluates the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train,Y_train, batch_size = None,epochs = epochs, validation_data = (X_val,Y_val), validation_steps=X_train.shape[0] // batch_size, steps_per_epoch=X_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>After we trained the model, plot the accuracy and loss versus epochs of both the train and validation(test) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(16, 10))\n",
    "ax[0,0].plot(history.history['acc'])\n",
    "ax[0,0].set_xlabel('Epoch')\n",
    "ax[0,0].set_ylabel('Accuracy')\n",
    "ax[0,0].set_title('Accuracy of Train')\n",
    "ax[0,1].plot(history.history['loss'])\n",
    "ax[0,1].set_xlabel('Epoch')\n",
    "ax[0,1].set_ylabel('Loss')\n",
    "ax[0,1].set_title('Loss of Train')\n",
    "ax[1,0].plot(history.history['val_acc'])\n",
    "ax[1,0].set_xlabel('Epoch')\n",
    "ax[1,0].set_ylabel('Accuracy')\n",
    "ax[1,0].set_title('Accuracy of Validation')\n",
    "ax[1,1].plot(history.history['val_loss'])\n",
    "ax[1,1].set_xlabel('Epoch')\n",
    "ax[1,1].set_ylabel('Loss')\n",
    "ax[1,1].set_title('Loss of Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>The accuracy is acceptable to some extent.\n",
    "<br>For more direct view of the fit, plot the confusion matrix of the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_val)\n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) #return the max of the axis\n",
    "Y_true = np.argmax(Y_val,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,linecolor=\"gray\", fmt= '.1f',ax=ax)#fmt refers to type of the data\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td bgcolor=lightyellow>Through the confusion matrix, we can see exactly how well the test set are predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>Inspired by the paper Super-resolving the Ising model with convolutional neural networks(https://arxiv.org/abs/1810.02372), we try to use CNN here to restore the decimated configurations of the Ising model back to the initial size with high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>For the network, the Y would be the initial configuration. To get the X, we firstly do the decimation(RG process) of the Ising model: divide the 2L * 2L lattice into 2x2 blocks where each block is transformed to a spin with the same state as the majority of spins in the block. If the total sign is zero, we take the sign of the upper left spin to make the procedure deterministic. Therefore, we get the L * L lattice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>Then, we increases the resolution from L × L to 2L × 2L by transforming each up (down) spin to a block of four up (down) spins(fig1.a). And the 2L x 2L lattice would be the X of the network, which has the same shape as the Y do but the configuration is different now. And the aim the the network is try to restore the physical observables(here we use magnetization) of X back to that of the Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>The core of the network is the convolutional layer. Each convolution layer takes a configuration X as input and applies the transformation \n",
    "f (W ∗ x + b), where ∗ denotes the convolution operation, W is the so-called filter, b is a bias vector. This function is known as an activation function and the typical choice is the rectified linear function ReLU(x) = max(0, x). The effect of each convolution is to combine local features within a nf × nf region (filter size). A consequence of this is that each convolution layer reduces the images size by eliminating the rightmost and bottom edges. To avoid truncating the image edge, we surround the original configurations with additional spins from the periodic boundary conditions, which is showed in fig 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./fig1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>We got initial data from Monte Carlo, and they are 200 configurations of 16 by 16 matrices for each T of totally 61 different Ts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "csvFile = open(\"cnn_example2.csv\")\n",
    "reader = csv.reader(csvFile)\n",
    "rows= [row for row in reader]\n",
    "cdata=np.array(rows)\n",
    "data_allT=np.zeros((61,np.array(rows[0]).size))\n",
    "for i in range(0,61):\n",
    "    data_allT[i]=cdata[2*i]             # because there are blank rows in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>first of all, we calculate the magnetization of initial lattice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_M_16_list=[]\n",
    "realt_list=[]\n",
    "for temp in range(0,61):\n",
    "    realt_list.append(1+temp*0.05)\n",
    "    data_here16=data_allT[temp]\n",
    "    data_tocalc=copy.deepcopy(data_here16).reshape(200,256)\n",
    "    m_16=0\n",
    "    for kk in range(0,200):\n",
    "        m_16=m_16+abs(np.sum(data_tocalc[kk])/256)\n",
    "    real_M_16_list.append(m_16/200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Network Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D,Activation,Reshape,Lambda\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>First, we define a periodic-boundary-condition layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbc_layer(x,pad=1):\n",
    "    from keras.backend import tile\n",
    "    L=x.shape[1]\n",
    "    y=tile(x,[1,2,2,1])\n",
    "    return y[:,:L+pad,:L+pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.losses import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>As this is a physics problem, we should also consider the loss of physical observables(magnetization and energy of the ising model here) when calculating the total loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate M\n",
    "def calculate_magnetization(state):\n",
    "    return K.expand_dims(K.mean(state, axis=(1, 2, 3)))\n",
    "#calculate E\n",
    "def calculate_energy2D(state, n_spins):\n",
    "    Ex = K.sum(state[:,:,1:] * state[:,:,:-1], axis=(1, 2))\n",
    "    Ey = K.sum(state[:,1:] * state[:,:-1], axis=(1, 2))\n",
    "    Ex+= K.sum(state[:,:,0] * state[:,:,-1], axis=1)\n",
    "    Ey+= K.sum(state[:,0,:] * state[:,-1,:], axis=1)\n",
    "    return -(Ex + Ey)[:, 0] / n_spins\n",
    "def cross_entropy_loss(y_true, y_pred, eps=0.0000001):\n",
    "    cross_entropy = y_true * K.log(y_pred + eps) + (1.0 -y_true) * K.log(1.0 - y_pred + eps)\n",
    "    return - K.mean(cross_entropy, axis=(1,2,3))\n",
    "def regularization(y_true, y_pred, mag_reg, en_reg, n_spins=0):\n",
    "    y_true = 2 * y_true - 1\n",
    "    y_pred = 2 * y_pred - 1\n",
    "    loss = 0\n",
    "    if mag_reg != 0.0:\n",
    "        mag_dif = K.square(calculate_magnetization(y_true) - calculate_magnetization(y_pred))\n",
    "        loss = loss + mag_reg * mag_dif\n",
    "    if en_reg != 0.0:\n",
    "        en_dif  = K.square(calculate_energy2D(y_true, n_spins=n_spins) - calculate_energy2D(y_pred, n_spins=n_spins))\n",
    "        loss = loss + en_reg * en_dif\n",
    "    return loss\n",
    "def create_basic_loss(y_true, y_pred, ce=True):\n",
    "    if ce:\n",
    "        return cross_entropy_loss(y_true, y_pred)\n",
    "    else:\n",
    "        return K.mean(mean_squared_error(y_true, y_pred), axis=(1,2))\n",
    "def create_loss(y_true, y_pred, ce=True, mag_reg=0.27, en_reg=0.25, n_spins=256):\n",
    "    loss = create_basic_loss(y_true, y_pred, ce=ce)\n",
    "    if mag_reg == 0.0 and en_reg == 0.0:\n",
    "        return loss\n",
    "    return loss + regularization(y_true, y_pred, mag_reg=mag_reg, en_reg=en_reg,n_spins=n_spins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>Actually, we use one network for configurations at one specific T. So we define a function of the network sturcture. Every time we add a convolutional layer, we add pbc_layer before it to avoid the loss of shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thismodel():\n",
    "    model2 = Sequential()\n",
    "    model2.add(Lambda(pbc_layer,arguments={'pad':5}))\n",
    "    model2.add(Conv2D(64,6,padding = 'valid',kernel_initializer='he_normal',activation ='relu'))\n",
    "    model2.add(Lambda(pbc_layer,arguments={'pad':0}))\n",
    "    model2.add(Conv2D(32,1,padding = 'valid',kernel_initializer='he_normal',activation ='relu'))\n",
    "    model2.add(Lambda(pbc_layer,arguments={'pad':2}))\n",
    "    model2.add(Conv2D(1,3,padding = 'valid',kernel_initializer='glorot_normal',activation ='sigmoid'))\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "    model2.compile(optimizer = optimizer , loss = create_loss, metrics=['accuracy'])  \n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>In the data preparation section, we know that there are 61 Ts in total. For simple display, we just pick a list of indices of Ts. Then, we set the Y and the X after decimation and increasing the resolution. After training, we use the network at each T to do prediction and compare the physical observables obtained from the predicted configuration and initial configuration. we simply write a loop to complte this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>first we set the T_list(just indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_list=[0,5,10,15,20,25,30,35,40,45,50,55,60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>then, start the main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list for physical measurements\n",
    "\n",
    "M_predict_16=[]\n",
    "M_predict_16_error=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1103 12:07:18.848133 19344 deprecation_wrapper.py:119] From c:\\工具\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1103 12:07:18.885032 19344 deprecation_wrapper.py:119] From c:\\工具\\python\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1103 12:07:18.888025 19344 deprecation_wrapper.py:119] From c:\\工具\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1103 12:07:18.907974 19344 deprecation_wrapper.py:119] From c:\\工具\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W1103 12:07:18.989267 19344 deprecation_wrapper.py:119] From c:\\工具\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1103 12:07:19.521332 19344 deprecation_wrapper.py:119] From c:\\工具\\python\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 265ms/step - loss: 1.3359 - acc: 0.6665 - val_loss: 0.1273 - val_acc: 0.9998\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.0400 - acc: 0.9996 - val_loss: 0.0063 - val_acc: 0.9998\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.0051 - acc: 0.9996 - val_loss: 0.0027 - val_acc: 0.9998\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 0.0022 - val_acc: 0.9998\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 0.9998\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 214ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 0.9998\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 0.9998\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 0.9998\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 215ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 0.9998\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 213ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0020 - val_acc: 0.9998\n",
      "0 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 2s 268ms/step - loss: 2.5798 - acc: 0.2229 - val_loss: 1.2164 - val_acc: 0.9969\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 215ms/step - loss: 0.4751 - acc: 0.9984 - val_loss: 0.0585 - val_acc: 0.9986\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 215ms/step - loss: 0.0284 - acc: 0.9985 - val_loss: 0.0132 - val_acc: 0.9986\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 222ms/step - loss: 0.0124 - acc: 0.9985 - val_loss: 0.0106 - val_acc: 0.9986\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 222ms/step - loss: 0.0115 - acc: 0.9985 - val_loss: 0.0104 - val_acc: 0.9986\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.0115 - acc: 0.9985 - val_loss: 0.0105 - val_acc: 0.9986\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 219ms/step - loss: 0.0116 - acc: 0.9985 - val_loss: 0.0104 - val_acc: 0.9986\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.0115 - acc: 0.9985 - val_loss: 0.0104 - val_acc: 0.9986\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 217ms/step - loss: 0.0115 - acc: 0.9985 - val_loss: 0.0104 - val_acc: 0.9986\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 221ms/step - loss: 0.0115 - acc: 0.9985 - val_loss: 0.0104 - val_acc: 0.9986\n",
      "5 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 279ms/step - loss: 0.3688 - acc: 0.9937 - val_loss: 0.0713 - val_acc: 0.9908\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 219ms/step - loss: 0.0440 - acc: 0.9937 - val_loss: 0.0562 - val_acc: 0.9908\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 220ms/step - loss: 0.0411 - acc: 0.9937 - val_loss: 0.0624 - val_acc: 0.9908\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 219ms/step - loss: 0.0428 - acc: 0.9937 - val_loss: 0.0622 - val_acc: 0.9908\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 220ms/step - loss: 0.0418 - acc: 0.9937 - val_loss: 0.0593 - val_acc: 0.9908\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.0395 - acc: 0.9937 - val_loss: 0.0547 - val_acc: 0.9908\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 0.0376 - acc: 0.9937 - val_loss: 0.0515 - val_acc: 0.9908\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 221ms/step - loss: 0.0374 - acc: 0.9937 - val_loss: 0.0515 - val_acc: 0.9908\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.0370 - acc: 0.9937 - val_loss: 0.0518 - val_acc: 0.9908\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 222ms/step - loss: 0.0367 - acc: 0.9937 - val_loss: 0.0509 - val_acc: 0.9908\n",
      "10 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 290ms/step - loss: 0.9373 - acc: 0.8606 - val_loss: 0.1407 - val_acc: 0.9834\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 221ms/step - loss: 0.0965 - acc: 0.9833 - val_loss: 0.0867 - val_acc: 0.9834\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.0922 - acc: 0.9833 - val_loss: 0.0957 - val_acc: 0.9834\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 233ms/step - loss: 0.0978 - acc: 0.9833 - val_loss: 0.0973 - val_acc: 0.9834\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.0972 - acc: 0.9833 - val_loss: 0.0948 - val_acc: 0.9834\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 222ms/step - loss: 0.0939 - acc: 0.9833 - val_loss: 0.0909 - val_acc: 0.9834\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 0.0899 - acc: 0.9833 - val_loss: 0.0872 - val_acc: 0.9834\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.0866 - acc: 0.9833 - val_loss: 0.0847 - val_acc: 0.9834\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 0.0845 - acc: 0.9833 - val_loss: 0.0831 - val_acc: 0.9834\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 223ms/step - loss: 0.0831 - acc: 0.9833 - val_loss: 0.0820 - val_acc: 0.9834\n",
      "15 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 302ms/step - loss: 0.3780 - acc: 0.9527 - val_loss: 0.2015 - val_acc: 0.9516\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 0.1886 - acc: 0.9574 - val_loss: 0.2270 - val_acc: 0.9516\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.2020 - acc: 0.9574 - val_loss: 0.2213 - val_acc: 0.9516\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 224ms/step - loss: 0.1891 - acc: 0.9574 - val_loss: 0.2003 - val_acc: 0.9516\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.1757 - acc: 0.9574 - val_loss: 0.1910 - val_acc: 0.9516\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.1728 - acc: 0.9575 - val_loss: 0.1878 - val_acc: 0.9516\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.1688 - acc: 0.9575 - val_loss: 0.1800 - val_acc: 0.9516\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.1615 - acc: 0.9576 - val_loss: 0.1701 - val_acc: 0.9516\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.1543 - acc: 0.9577 - val_loss: 0.1614 - val_acc: 0.9529\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.1476 - acc: 0.9592 - val_loss: 0.1539 - val_acc: 0.9572\n",
      "20 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 311ms/step - loss: 0.8153 - acc: 0.7230 - val_loss: 0.4274 - val_acc: 0.8527\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 225ms/step - loss: 0.4421 - acc: 0.8560 - val_loss: 0.4536 - val_acc: 0.8600\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.4408 - acc: 0.8600 - val_loss: 0.4053 - val_acc: 0.8629\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 237ms/step - loss: 0.3875 - acc: 0.8643 - val_loss: 0.3745 - val_acc: 0.8637\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.3700 - acc: 0.8673 - val_loss: 0.3612 - val_acc: 0.8713\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.3522 - acc: 0.8732 - val_loss: 0.3411 - val_acc: 0.8785\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 226ms/step - loss: 0.3392 - acc: 0.8788 - val_loss: 0.3266 - val_acc: 0.8883\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.3264 - acc: 0.8859 - val_loss: 0.3140 - val_acc: 0.8953\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.3153 - acc: 0.8921 - val_loss: 0.3029 - val_acc: 0.8986\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 234ms/step - loss: 0.3054 - acc: 0.8948 - val_loss: 0.2934 - val_acc: 0.9025\n",
      "25 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 324ms/step - loss: 0.9669 - acc: 0.5414 - val_loss: 0.8406 - val_acc: 0.6359\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.7611 - acc: 0.6478 - val_loss: 0.6828 - val_acc: 0.6959\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.6780 - acc: 0.6854 - val_loss: 0.5957 - val_acc: 0.7381\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.5982 - acc: 0.7342 - val_loss: 0.5427 - val_acc: 0.7689\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.5439 - acc: 0.7618 - val_loss: 0.5072 - val_acc: 0.7799\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.5090 - acc: 0.7816 - val_loss: 0.4795 - val_acc: 0.7953\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.4800 - acc: 0.7987 - val_loss: 0.4547 - val_acc: 0.8092\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.4597 - acc: 0.8130 - val_loss: 0.4349 - val_acc: 0.8246\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.4437 - acc: 0.8227 - val_loss: 0.4200 - val_acc: 0.8320\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.4314 - acc: 0.8286 - val_loss: 0.4086 - val_acc: 0.8369\n",
      "30 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 0.9257 - acc: 0.5135 - val_loss: 0.8010 - val_acc: 0.5793\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.7954 - acc: 0.5893 - val_loss: 0.7186 - val_acc: 0.6385\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.7116 - acc: 0.6482 - val_loss: 0.6443 - val_acc: 0.6939\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.6508 - acc: 0.6907 - val_loss: 0.5998 - val_acc: 0.7188\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.6059 - acc: 0.7183 - val_loss: 0.5695 - val_acc: 0.7377\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.5695 - acc: 0.7393 - val_loss: 0.5426 - val_acc: 0.7549\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.5401 - acc: 0.7557 - val_loss: 0.5187 - val_acc: 0.7691\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 227ms/step - loss: 0.5170 - acc: 0.7721 - val_loss: 0.5010 - val_acc: 0.7850\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.4986 - acc: 0.7857 - val_loss: 0.4868 - val_acc: 0.7943\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.4847 - acc: 0.7947 - val_loss: 0.4755 - val_acc: 0.8010\n",
      "35 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 352ms/step - loss: 0.8705 - acc: 0.5322 - val_loss: 0.7947 - val_acc: 0.5811\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.7494 - acc: 0.6098 - val_loss: 0.6971 - val_acc: 0.6568\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.6649 - acc: 0.6729 - val_loss: 0.6316 - val_acc: 0.7037\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 228ms/step - loss: 0.6067 - acc: 0.7126 - val_loss: 0.5844 - val_acc: 0.7432\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.5675 - acc: 0.7424 - val_loss: 0.5551 - val_acc: 0.7557\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.5410 - acc: 0.7580 - val_loss: 0.5356 - val_acc: 0.7650\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.5227 - acc: 0.7699 - val_loss: 0.5229 - val_acc: 0.7752\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 239ms/step - loss: 0.5101 - acc: 0.7795 - val_loss: 0.5140 - val_acc: 0.7811\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.5009 - acc: 0.7856 - val_loss: 0.5077 - val_acc: 0.7850\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.4940 - acc: 0.7918 - val_loss: 0.5034 - val_acc: 0.7906\n",
      "40 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 352ms/step - loss: 0.9321 - acc: 0.4795 - val_loss: 0.9043 - val_acc: 0.4854\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.8443 - acc: 0.5266 - val_loss: 0.8199 - val_acc: 0.5488\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.7846 - acc: 0.5685 - val_loss: 0.7667 - val_acc: 0.5850\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.7366 - acc: 0.6099 - val_loss: 0.7246 - val_acc: 0.6180\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.6948 - acc: 0.6414 - val_loss: 0.6878 - val_acc: 0.6510\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.6572 - acc: 0.6717 - val_loss: 0.6519 - val_acc: 0.6789\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.6237 - acc: 0.6988 - val_loss: 0.6225 - val_acc: 0.7035\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.5959 - acc: 0.7190 - val_loss: 0.5996 - val_acc: 0.7230\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.5741 - acc: 0.7343 - val_loss: 0.5821 - val_acc: 0.7322\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.5570 - acc: 0.7449 - val_loss: 0.5687 - val_acc: 0.7441\n",
      "45 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 358ms/step - loss: 0.9208 - acc: 0.4980 - val_loss: 0.8774 - val_acc: 0.5092\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.8208 - acc: 0.5447 - val_loss: 0.7898 - val_acc: 0.5604\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 229ms/step - loss: 0.7531 - acc: 0.5876 - val_loss: 0.7364 - val_acc: 0.6084\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 230ms/step - loss: 0.7003 - acc: 0.6330 - val_loss: 0.6884 - val_acc: 0.6373\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.6551 - acc: 0.6689 - val_loss: 0.6446 - val_acc: 0.6705\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.6187 - acc: 0.6966 - val_loss: 0.6130 - val_acc: 0.6998\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 243ms/step - loss: 0.5914 - acc: 0.7190 - val_loss: 0.5869 - val_acc: 0.7217\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 0.5716 - acc: 0.7347 - val_loss: 0.5695 - val_acc: 0.7361\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 0.5575 - acc: 0.7450 - val_loss: 0.5572 - val_acc: 0.7482\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 233ms/step - loss: 0.5470 - acc: 0.7523 - val_loss: 0.5481 - val_acc: 0.7543\n",
      "50 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 3s 368ms/step - loss: 0.8364 - acc: 0.5317 - val_loss: 0.7833 - val_acc: 0.5562\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 0.7403 - acc: 0.5941 - val_loss: 0.7106 - val_acc: 0.6137\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 233ms/step - loss: 0.6743 - acc: 0.6456 - val_loss: 0.6622 - val_acc: 0.6590\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 235ms/step - loss: 0.6302 - acc: 0.6825 - val_loss: 0.6318 - val_acc: 0.6877\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 233ms/step - loss: 0.6015 - acc: 0.7078 - val_loss: 0.6108 - val_acc: 0.7080\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 0.5807 - acc: 0.7253 - val_loss: 0.5948 - val_acc: 0.7211\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 234ms/step - loss: 0.5653 - acc: 0.7375 - val_loss: 0.5827 - val_acc: 0.7268\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 0.5541 - acc: 0.7460 - val_loss: 0.5738 - val_acc: 0.7342\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 233ms/step - loss: 0.5459 - acc: 0.7535 - val_loss: 0.5676 - val_acc: 0.7418\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 0.5397 - acc: 0.7595 - val_loss: 0.5630 - val_acc: 0.7484\n",
      "55 done\n",
      "Train on 180 samples, validate on 20 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 382ms/step - loss: 0.8292 - acc: 0.5035 - val_loss: 0.7754 - val_acc: 0.5447\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.7567 - acc: 0.5621 - val_loss: 0.7152 - val_acc: 0.6109\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 2s 231ms/step - loss: 0.7088 - acc: 0.6094 - val_loss: 0.6729 - val_acc: 0.6447\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 0.6696 - acc: 0.6405 - val_loss: 0.6385 - val_acc: 0.6811\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 0.6353 - acc: 0.6766 - val_loss: 0.6117 - val_acc: 0.7006\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 2s 235ms/step - loss: 0.6070 - acc: 0.7032 - val_loss: 0.5907 - val_acc: 0.7170\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 2s 234ms/step - loss: 0.5850 - acc: 0.7217 - val_loss: 0.5757 - val_acc: 0.7318\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 2s 232ms/step - loss: 0.5689 - acc: 0.7351 - val_loss: 0.5653 - val_acc: 0.7443\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 2s 235ms/step - loss: 0.5578 - acc: 0.7458 - val_loss: 0.5585 - val_acc: 0.7502\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 2s 233ms/step - loss: 0.5501 - acc: 0.7521 - val_loss: 0.5543 - val_acc: 0.7510\n",
      "60 done\n"
     ]
    }
   ],
   "source": [
    "for eacht in T_list:\n",
    "    data_separate=copy.deepcopy(data_allT[eacht]).reshape(200,256) # configuration at a specific T\n",
    "    Y_train=copy.deepcopy(data_separate)       # set the Y\n",
    "    \n",
    "    # for configuration, we use -1 and 1 at each site, but we have to change -1 into 0 for the use of network\n",
    "    \n",
    "    for i in range(0,len(Y_train)):\n",
    "        for j in range(0,256):\n",
    "            if Y_train[i,j]==-1:\n",
    "                Y_train[i,j]=0\n",
    "            else:\n",
    "                Y_train[i,j]=1\n",
    "    Y_train=Y_train.reshape(-1,16,16,1)          # reshape the tensor for the use of network\n",
    "    \n",
    "    # do the decimation\n",
    "    \n",
    "    data_dec=np.zeros((200,64))                 # 16x16->8x8\n",
    "    data_T=copy.deepcopy(data_separate)\n",
    "    for i in range(0,200):\n",
    "        ini=data_T[i]\n",
    "        for ii in range(0,8):\n",
    "            for iii in range(0,8):\n",
    "                x=2*ii+32*iii\n",
    "                sum=ini[x]+ini[x+1]+ini[x+16]+ini[x+17]\n",
    "                if sum >= 0:\n",
    "                    data_dec[i,ii+iii*8]=1\n",
    "                else:\n",
    "                    data_dec[i,ii+iii*8]=-1\n",
    "    \n",
    "    # increases the resolution from 8 × 8 to 16 × 16 by transforming each up (down) spin to a block of four up (down) spins\n",
    "    \n",
    "    data_return=np.zeros((200,256))\n",
    "    for i in range(0,200):\n",
    "        for ii in range(0,8):\n",
    "            for iii in range(0,8):\n",
    "                x=2*ii+32*iii\n",
    "                this=data_dec[i,ii+iii*8]\n",
    "                data_return[i,x]=this\n",
    "                data_return[i,x+1]=this\n",
    "                data_return[i,x+16]=this\n",
    "                data_return[i,x+17]=this\n",
    "    #set X\n",
    "    \n",
    "    X_train=copy.deepcopy(data_return).reshape(-1,16,16,1)\n",
    "    \n",
    "    # initialize model\n",
    "    \n",
    "    this_model=thismodel()\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=42)\n",
    "    epochs=10\n",
    "    batch_size = 20\n",
    "    \n",
    "    # fit the model\n",
    "    this_model.fit(X_train,Y_train, batch_size = None,epochs = epochs, validation_data = (X_val,Y_val), validation_steps=X_train.shape[0] // batch_size, steps_per_epoch=X_train.shape[0] // batch_size)\n",
    "    \n",
    "    #do prediction\n",
    "    \n",
    "    pre=this_model.predict(data_return.reshape(-1,16,16,1))\n",
    "    pre_re=copy.deepcopy(pre.reshape(-1,256))\n",
    "    \n",
    "    for ii in range(0,len(pre_re)):     #change 0 back into -1\n",
    "        for j in range(0,256):\n",
    "            pre_re[ii,j]=pre_re[ii,j]*2-1 \n",
    "    \n",
    "    # calculate M form predicted configuration\n",
    "    \n",
    "    forT2=pre_re\n",
    "    M22=[]\n",
    "    for jj in range(0,200):\n",
    "        M22.append(abs(np.sum(forT2[jj])/256))\n",
    "    M_predict_16.append(np.mean(M22))\n",
    "    M_predict_16_error.append(np.std(M22)/np.sqrt(200))\n",
    "    print(eacht,'done')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>As the T_list is of indices, we have to change it into a list of Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tlist=[]\n",
    "for i in T_list:\n",
    "    predict_tlist.append(1+i*0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>draw the errorbar to compare the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'M')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(realt_list,real_M_16_list,label='real result')\n",
    "plt.errorbar(predict_tlist,M_predict_16,yerr=M_predict_16_error,fmt='o',ecolor='hotpink',elinewidth=1,ms=5,mfc='wheat',mec='salmon',capsize=3,label='predicted result')\n",
    "plt.legend()\n",
    "plt.xlabel('T')\n",
    "plt.ylabel('M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = darkblue>As shown in the figure above, the neural network work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
